{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0252756-3b95-4b15-af7f-a60b8b3a2af7",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0c95e98-cc5d-4b51-bc77-50e73118100a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import chess\n",
    "import chess.pgn\n",
    "import chess.engine\n",
    "import chess.svg\n",
    "\n",
    "import io\n",
    "import time\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from IPython.display import display,SVG,clear_output \n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94c84e55-9b20-40a3-a571-3fd1dd70a65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionarios\n",
    "capa_pieza = {'p': 1, 'r': 3, 'n': 5, 'b': 7, 'q': 9, 'k': 11, 'P': 0, 'R': 2, 'N': 4, 'B': 6, 'Q': 8, 'K': 10}\n",
    "\n",
    "numero_letra = {0: 'a', 1: 'b', 2: 'c', 3: 'd', 4: 'e', 5: 'f', 6: 'g', 7: 'h'}\n",
    "\n",
    "letra_numero = {'a': 0, 'b': 1, 'c': 2, 'd':3 , 'e': 4, 'f': 5, 'g':6 , 'h': 7}\n",
    "\n",
    "\n",
    "# representación tablero\n",
    "def representacion_tablero(board,verbose=False):\n",
    "    fen = board.fen().split()\n",
    "    tablero_piezas_fen = fen[0]\n",
    "    turno_fen = fen[1]\n",
    "    enroque_fen = fen[2]\n",
    "    enpassant_fen = fen[3]\n",
    "\n",
    "    tablero_r = np.zeros((8,8,22),dtype=np.float32)\n",
    "\n",
    "    fila=0\n",
    "    columna=0\n",
    "    \n",
    "    for caracter in tablero_piezas_fen:\n",
    "        \n",
    "        if not caracter.isdigit():\n",
    "         \n",
    "            if caracter == '/':\n",
    "                fila+=1\n",
    "                columna=0\n",
    "           \n",
    "            else:\n",
    "    \n",
    "                tablero_r[fila][columna][capa_pieza[caracter]]=1\n",
    "                columna+=1\n",
    "                \n",
    "        else:\n",
    "            columna+= int(caracter)\n",
    "\n",
    "    if turno_fen == 'w':\n",
    "        tablero_r[:, :, 12] = 1\n",
    "    if 'K' in enroque_fen:\n",
    "        tablero_r[:, :, 13] = 1\n",
    "    if 'k' in enroque_fen:\n",
    "        tablero_r[:, :, 14] = 1\n",
    "    if 'Q' in enroque_fen:\n",
    "        tablero_r[:, :, 15] = 1\n",
    "    if 'q' in enroque_fen:\n",
    "        tablero_r[:, :, 16] = 1\n",
    "           \n",
    "\n",
    "    if enpassant_fen != \"-\":\n",
    "        tablero_r[8-int(enpassant_fen[1])][letra_numero[enpassant_fen[0]]][17] = 1\n",
    "\n",
    "\n",
    "    for square in chess.SQUARES:\n",
    "        row = 7 - (square // 8)\n",
    "        col = square % 8  \n",
    "        tablero_r[row, col, 18] = len(board.attackers(chess.WHITE, square))/10\n",
    "        tablero_r[row, col, 19] = len(board.attackers(chess.BLACK, square))/10\n",
    "\n",
    "    for move in board.legal_moves:\n",
    "        to_square = move.to_square\n",
    "        row = 7 - (to_square // 8)\n",
    "        col = to_square % 8\n",
    "        tablero_r[row][col][20] = 1\n",
    "\n",
    "    if board.is_check():\n",
    "        tablero_r[:, :, 21] = 1\n",
    "\n",
    "\n",
    "    if turno_fen == 'b':\n",
    "        tablero_r = np.flip(tablero_r[:, :, :22], axis=(0, 1)).copy()\n",
    "\n",
    "    if verbose:       \n",
    "        for capa in range(22):\n",
    "             for fila in range(8):\n",
    "                 for columna in range(8):\n",
    "                     print(tablero_r[fila][columna][capa], end=\"\")\n",
    "                     print(\" \",end=\"\")\n",
    "                 print(\" \")\n",
    "             print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "    return tablero_r\n",
    "\n",
    "\n",
    "\n",
    "# representación movimiento\n",
    "def move_to_policy(uci_move,turn,verbose=False):\n",
    "    move = np.zeros((8,8,2),dtype=np.float32)\n",
    "    casilla_origen = uci_move[:2]\n",
    "    casilla_destino = uci_move[2:4]\n",
    "\n",
    "    casilla_origen_columna = letra_numero[casilla_origen[0]]\n",
    "    casilla_origen_fila = casilla_origen[1]\n",
    "    \n",
    "    casilla_destino_columna = letra_numero[casilla_destino[0]]\n",
    "    casilla_destino_fila = casilla_destino[1]\n",
    "\n",
    "\n",
    "    casilla_origen_fila = 8 - int(casilla_origen_fila)\n",
    "\n",
    "    casilla_destino_fila = 8 - int(casilla_destino_fila)\n",
    "\n",
    "\n",
    "    move[casilla_origen_fila][casilla_origen_columna][0]=1\n",
    "    move[casilla_destino_fila][casilla_destino_columna][1]=1\n",
    "\n",
    "    if turn != chess.WHITE:\n",
    "        move = np.flip(move[:, :, :2], axis=(0, 1)).copy()\n",
    "\n",
    "    if verbose:\n",
    "        for capa in range(2):\n",
    "             for fila in range(8):\n",
    "                 for columna in range(8):\n",
    "                     print(move[fila][columna][capa], end=\"\")\n",
    "                     print(\" \",end=\"\")\n",
    "                 print(\" \")\n",
    "             print(\"\\n\")\n",
    "        \n",
    "        \n",
    "    return move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "066a2e4b-2777-4ba9-9256-9e2b4905aad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de entrenamiento: 17555\n",
      "Tamaño del conjunto de prueba: 1951\n",
      "Estructura del batch: \n",
      "Posición batch shape: torch.Size([256, 22, 8, 8])\n",
      "Movimiento batch shape: torch.Size([256, 2, 8, 8])\n",
      "Evaluación batch shape: torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, partidas_file, transform=None, target_transform=None):\n",
    "\n",
    "        self.partidas_file = partidas_file\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.posiciones = None\n",
    "        self.keys = None\n",
    "        self.archivo = None\n",
    "        \n",
    "        with h5py.File(partidas_file, 'r') as archivo:\n",
    " \n",
    "            game_keys = np.array(list(archivo['posiciones'].keys()))\n",
    "            array_posiciones = np.zeros(len(game_keys),dtype=np.uint32)\n",
    "            positions = 0\n",
    "            for i, game_key in enumerate(game_keys):\n",
    "                positions += archivo['posiciones'][game_key].shape[0]\n",
    "                array_posiciones[i]=  positions\n",
    "           \n",
    "        self.posiciones =  array_posiciones\n",
    "        self.keys =  game_keys\n",
    "        self.total_positions = self.posiciones[-1]\n",
    "        self.half_positions = self.total_positions // 50# Calcular la mitad del dataset\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.half_positions\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        if self.archivo is None:\n",
    "            self.archivo = h5py.File(self.partidas_file, 'r')\n",
    "        \n",
    "        game_idx, position_idx = self.binary_search_iterative(idx)\n",
    "        \n",
    "        grupo_posiciones = self.archivo['posiciones']\n",
    "        grupo_movimientos = self.archivo['movimientos']\n",
    "        grupo_evaluaciones = self.archivo['evaluaciones']\n",
    "\n",
    "        key_posiciones = self.keys[game_idx]\n",
    "        key_movimientos = key_posiciones.replace(\"board\", \"mov\")\n",
    "        key_evaluaciones = key_posiciones.replace(\"board\", \"eval\")\n",
    "\n",
    "        posicion = grupo_posiciones[key_posiciones][position_idx]\n",
    "        movimiento = grupo_movimientos[key_movimientos][position_idx]\n",
    "        evaluacion = grupo_evaluaciones[key_evaluaciones][position_idx]\n",
    "\n",
    "        if self.transform:\n",
    "            posicion = self.transform(posicion)\n",
    "            movimiento = self.transform(movimiento)\n",
    "\n",
    "        if self.target_transform:\n",
    "            pass\n",
    "            #evaluacion = self.target_transform(evaluacion)\n",
    "\n",
    "        return posicion, movimiento, evaluacion\n",
    "\n",
    "\n",
    "    def binary_search_iterative(self, x):\n",
    "        \n",
    "        left, right = 0, len(self.posiciones) - 1\n",
    "        while left <= right:\n",
    "            mid = (left + right) // 2\n",
    "            if self.posiciones[mid] == x:\n",
    "                indice = 0\n",
    "                return mid+1,indice\n",
    "            elif self.posiciones[mid] < x:\n",
    "                left = mid + 1\n",
    "            else:\n",
    "                right = mid - 1\n",
    "       \n",
    "    \n",
    "        if left!=0:\n",
    "            indice = x-self.posiciones[left-1]\n",
    "        else:\n",
    "            indice = x\n",
    "        return left,indice\n",
    "        \n",
    "partidas_file = 'dataset.h5'  # Reemplaza con la ruta a tu archivo h5\n",
    "to_tensor = ToTensor()\n",
    "\n",
    "# Crear el dataset\n",
    "dataset = CustomDataset(partidas_file,transform=to_tensor)\n",
    "        \n",
    "# Define el tamaño de los conjuntos de entrenamiento y prueba\n",
    "train_size = int(0.9 * len(dataset))  # 90% para entrenamiento\n",
    "test_size = len(dataset) - train_size  # 10% para prueba\n",
    "\n",
    "# Divide el dataset en entrenamiento y prueba\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "print(f\"Tamaño del conjunto de entrenamiento: {len(train_dataset)}\")\n",
    "print(f\"Tamaño del conjunto de prueba: {len(test_dataset)}\")\n",
    "train_loader = DataLoader(train_dataset, batch_size=256)\n",
    "test_loader = DataLoader(test_dataset, shuffle=True,batch_size=256)\n",
    "\n",
    "iterador =  iter(train_loader) \n",
    "positions,mov,eval = next(iterador)\n",
    "\n",
    "print(\"Estructura del batch: \")\n",
    "print(f\"Posición batch shape: {positions.size()}\")\n",
    "print(f\"Movimiento batch shape: {mov.size()}\")\n",
    "print(f\"Evaluación batch shape: {eval.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "963d45a1-16fb-48d0-bab9-c47c9fa63591",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, num_resBlocks, num_hidden):\n",
    "        super().__init__()\n",
    "        self.startBlock = nn.Sequential(\n",
    "            nn.Conv2d(22, num_hidden, kernel_size=3, padding=1,bias=False),\n",
    "            nn.BatchNorm2d(num_hidden),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.backBone = nn.ModuleList(\n",
    "            [ResBlock(num_hidden) for i in range(num_resBlocks)]\n",
    "        )\n",
    "        \n",
    "        self.policyHead = nn.Sequential(\n",
    "            nn.Conv2d(num_hidden, num_hidden, kernel_size=3,padding=1,bias=False),\n",
    "            nn.BatchNorm2d(num_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(num_hidden, 2, kernel_size=3,padding=1),\n",
    "        )\n",
    "\n",
    "        self.valueHead = nn.Sequential(\n",
    "            nn.Conv2d(num_hidden, 3, kernel_size=3,padding=1,bias=False),\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3 * 8 * 8, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.startBlock(x)\n",
    "        for resBlock in self.backBone:\n",
    "            x = resBlock(x)\n",
    "        policy = self.policyHead(x)\n",
    "        value =  self.valueHead(x)\n",
    "        return policy,value\n",
    "    \n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, num_hidden):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(num_hidden, num_hidden, kernel_size=3, padding=1,bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(num_hidden)\n",
    "        self.conv2 = nn.Conv2d(num_hidden, num_hidden, kernel_size=3, padding=1,bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(num_hidden)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x += residual\n",
    "        x = F.relu(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b262f338-4b81-4e2b-abeb-1fd1c0f6a426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer):\n",
    "    \n",
    "    model.train()\n",
    "    loss_v = 0\n",
    "\n",
    "    for posicion, movimiento, evaluacion in train_loader:\n",
    "    \n",
    "        posicion, movimiento,evaluacion = posicion.to(device), movimiento.to(device), evaluacion.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output,value = model(posicion) \n",
    "\n",
    "        lossP = F.cross_entropy(output[:,0,:], movimiento[:,0,:])\n",
    "        lossP1 = F.cross_entropy(output[:,1,:], movimiento[:,1,:])\n",
    "        lossV = F.mse_loss(value.view(-1), evaluacion)\n",
    "\n",
    "        loss = lossP+lossP1+lossV\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_v += loss.item()\n",
    "      \n",
    "\n",
    "    loss_v /= len(train_loader)\n",
    "    return loss_v\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for posicion, movimiento, evaluacion in test_loader:\n",
    "            \n",
    "            posicion, movimiento,evaluacion = posicion.to(device), movimiento.to(device), evaluacion.to(device)\n",
    "            output,value = model(posicion) \n",
    "\n",
    "            lossP = F.cross_entropy(output[:,0,:], movimiento[:,0,:])\n",
    "            lossP1 = F.cross_entropy(output[:,1,:], movimiento[:,1,:])\n",
    "            lossV = F.mse_loss(value.view(-1), evaluacion)\n",
    "\n",
    "            loss = lossP+lossP1+lossV\n",
    "            test_loss +=  loss.item()\n",
    "          \n",
    "    test_loss /= len(test_loader)\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a28adc3f-2a43-4133-b323-da8321207a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Epoch 1/10 ===\n",
      "Pérdida de entrenamiento: 1.1278706745824951\n",
      "Pérdida de validación : 0.8966252729296684\n",
      "\n",
      "=== Epoch 2/10 ===\n",
      "Pérdida de entrenamiento: 0.7211151429708453\n",
      "Pérdida de validación : 0.6589106097817421\n",
      "\n",
      "=== Epoch 3/10 ===\n",
      "Pérdida de entrenamiento: 0.5051594782566678\n",
      "Pérdida de validación : 0.5921506434679031\n",
      "\n",
      "=== Epoch 4/10 ===\n",
      "Pérdida de entrenamiento: 0.38405791702477826\n",
      "Pérdida de validación : 0.521225344389677\n",
      "\n",
      "=== Epoch 5/10 ===\n",
      "Pérdida de entrenamiento: 0.3184693481611169\n",
      "Pérdida de validación : 0.4998319074511528\n",
      "\n",
      "=== Epoch 6/10 ===\n",
      "Pérdida de entrenamiento: 0.27249957988227624\n",
      "Pérdida de validación : 0.4816940873861313\n",
      "\n",
      "=== Epoch 7/10 ===\n",
      "Pérdida de entrenamiento: 0.23816967183265134\n",
      "Pérdida de validación : 0.47409604489803314\n",
      "\n",
      "=== Epoch 8/10 ===\n",
      "Pérdida de entrenamiento: 0.20708697710348212\n",
      "Pérdida de validación : 0.47348760440945625\n",
      "\n",
      "=== Epoch 9/10 ===\n",
      "Pérdida de entrenamiento: 0.18330738790657208\n",
      "Pérdida de validación : 0.46843351796269417\n",
      "\n",
      "=== Epoch 10/10 ===\n",
      "Pérdida de entrenamiento: 0.15881967177425604\n",
      "Pérdida de validación : 0.45753271877765656\n",
      "Tiempo transcurrido: 174.90273928642273 segundos\n"
     ]
    }
   ],
   "source": [
    "#torch.manual_seed(33)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "modelSimple = ResNet(10, 256).to(device)\n",
    "\n",
    "lr = 0.01\n",
    "\n",
    "optimizer = optim.SGD(modelSimple.parameters(), lr=lr,weight_decay=0.001)\n",
    "\n",
    "\n",
    "# Guardam el valor de peèrdua mig de cada iteració (època)\n",
    "train_l = np.zeros((epochs))\n",
    "test_l = np.zeros((epochs))\n",
    "\n",
    "    #pbar = tqdm(range(1, epochs+1))\n",
    "\n",
    "tiempo_inicial = time.time()  # Obtener el tiempo inicial\n",
    "\n",
    "    # Bucle d'entrenament\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n=== Epoch {epoch + 1}/{epochs} ===\")\n",
    "    \n",
    "    train_l[epoch] = train(modelSimple, device, train_loader, optimizer)\n",
    "    test_l[epoch]  = test(modelSimple, device, test_loader)\n",
    "    \n",
    "    print(f\"Pérdida de entrenamiento: {train_l[epoch]}\")\n",
    "    print(f\"Pérdida de validación : {test_l[epoch]}\")\n",
    "\n",
    "tiempo_final = time.time()  \n",
    "    # Obtener el tiempo final\n",
    "tiempo_transcurrido = tiempo_final - tiempo_inicial  # Calcular el tiempo transcurrido\n",
    "        \n",
    "print(\"Tiempo transcurrido:\", tiempo_transcurrido, \"segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8073aa49-b5a6-421a-9155-e837c31c3259",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(modelSimple.state_dict(), 'modelo_pesos.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c70b09f8-428c-4f98-be3d-188bd4d9e9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy casilla inicial: 0.34495130702203997\n",
      "Accuracy casilla final: 0.25627883136852897\n",
      "Accuracy evaluación: 0.8206048180420298\n"
     ]
    }
   ],
   "source": [
    "modelSimple.eval()\n",
    "\n",
    "correct_posicion_inicial = 0\n",
    "correct_posicion_final = 0\n",
    "correct_eval = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for posicion, movimiento, evaluacion in test_loader:     \n",
    "        posicion, movimiento, evaluacion = posicion.to(device), movimiento.to(device), evaluacion.to(device)\n",
    "        output, value = modelSimple(posicion) \n",
    "\n",
    "        # Obtener los índices máximos para cada muestra en el batch\n",
    "        _, indices_origen = torch.max(output[:, 0, :, :].view(output.size(0), -1), dim=1)\n",
    "        _, indices_movimiento_origen = torch.max(movimiento[:, 0, :, :].view(movimiento.size(0), -1), dim=1)\n",
    "\n",
    "        _, indices_final = torch.max(output[:, 1, :, :].view(output.size(0), -1), dim=1)\n",
    "        _, indices_movimiento_final = torch.max(movimiento[:, 1, :, :].view(movimiento.size(0), -1), dim=1)\n",
    "\n",
    "        # Contar las predicciones correctas\n",
    "        correct_posicion_inicial += torch.sum(indices_origen == indices_movimiento_origen).item()\n",
    "        correct_posicion_final += torch.sum(indices_final == indices_movimiento_final).item()\n",
    "\n",
    "        # Redondear las predicciones del modelo a los valores enteros más cercanos (-1, 0, 1)\n",
    "        rounded_value = torch.where(value >= 0.2, torch.tensor(1.0), torch.where(value <= -0.2, torch.tensor(-1.0), torch.tensor(0.0)))\n",
    "\n",
    "        # Contar las predicciones de evaluación correctas\n",
    "        correct_eval += torch.sum(rounded_value.squeeze() == evaluacion).item()\n",
    "\n",
    "        total += posicion.size(0)  # Sumar el tamaño del batch\n",
    " \n",
    "# Calcular la precisión total\n",
    "accuracy_origen = correct_posicion_inicial / total\n",
    "accuracy_final = correct_posicion_final / total  \n",
    "accuracy_eval = correct_eval / total\n",
    "\n",
    "print(f'Accuracy casilla inicial: {accuracy_origen}')\n",
    "print(f'Accuracy casilla final: {accuracy_final}')\n",
    "print(f'Accuracy evaluación: {accuracy_eval}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4306ce-579f-4108-88ac-79bf90820423",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
